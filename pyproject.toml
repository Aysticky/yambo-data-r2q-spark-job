[tool.poetry]
name = "yambo-data-r2q-spark-job"
version = "0.1.0"
description = "Enterprise-grade REST API to S3 data pipeline using Apache Spark on AWS EKS"
authors = ["Yambo Platform Team <platform@yambo.com>"]
readme = "README.md"
packages = [{include = "src"}]

[tool.poetry.dependencies]
python = ">=3.9,<3.13"
pyspark = "^3.5.0"
requests = "^2.31.0"
boto3 = "^1.34.0"
python-dateutil = "^2.8.2"
pydantic = "^2.5.0"
tenacity = "^8.2.3"
stripe = "^7.10.0"
pyarrow = "^14.0.0"
pandas = "^2.1.0"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.3"
pytest-cov = "^4.1.0"
pytest-mock = "^3.12.0"
black = "^23.12.1"
flake8 = "^6.1.0"
mypy = "^1.7.1"
isort = "^5.13.2"
boto3-stubs = {extras = ["s3", "secretsmanager", "dynamodb"], version = "^1.34.0"}
moto = "^4.2.11"

[tool.poetry.group.airflow.dependencies]
apache-airflow = "^2.8.0"
apache-airflow-providers-amazon = "^8.15.0"
apache-airflow-providers-cncf-kubernetes = "^8.0.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 100
target-version = ['py39']
include = '\.pyi?$'
exclude = '''
/(
    \.git
  | \.venv
  | \.terraform
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
line_length = 100
skip = [".venv", ".terraform", "build", "dist"]

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --cov=src --cov-report=html --cov-report=term"
